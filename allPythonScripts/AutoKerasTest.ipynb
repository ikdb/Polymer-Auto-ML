{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "                                                 Smile  \\\n",
      "0                                              [*]C[*]   \n",
      "1                                          [*]CC([*])C   \n",
      "2                                         [*]CC([*])CC   \n",
      "3                                        [*]CC([*])CCC   \n",
      "4                                     [*]CC([*])CC(C)C   \n",
      "...                                                ...   \n",
      "3375           [*]Nc1c([2H])c([2H])c([*])c([2H])c1[2H]   \n",
      "3376               [*]CCCCCC[N+](C)(C)CCC[N+]([*])(C)C   \n",
      "3377          [*]CCCCCCCC[N+](C)(C)CCCCCC[N+]([*])(C)C   \n",
      "3378  [*]CCCCCCCCCCCCCCCC[N+](C)(C)CCCCCC[N+]([*])(C)C   \n",
      "3379       [*]C=Cc1cc([Si](C)(C)C)c([*])cc1[Si](C)(C)C   \n",
      "\n",
      "                                          Finger_prints     Egc  \n",
      "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  6.8972  \n",
      "1     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  6.5196  \n",
      "2     [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  6.5170  \n",
      "3     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  6.7336  \n",
      "4     [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  6.7394  \n",
      "...                                                 ...     ...  \n",
      "3375  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  3.3666  \n",
      "3376  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.2161  \n",
      "3377  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.1032  \n",
      "3378  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.1771  \n",
      "3379  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  2.2084  \n",
      "\n",
      "[3380 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from psmiles import PolymerSmiles as PS\n",
    "import pandas as pd\n",
    "# Read csv and filter EGC\n",
    "egc_df = pd.read_csv(\"/home/ibrahim/recources/export.csv\")\n",
    "egc_df = egc_df[egc_df.property == \"Egc\"]\n",
    "\n",
    "#creating fingerprints for SS\n",
    "smile_string_list = list(egc_df.smiles.values)\n",
    "value_list = list(egc_df.value.values)\n",
    "finger_print_list = []\n",
    "for ss in smile_string_list:\n",
    "    curren_polymere = PS(ss)\n",
    "    \n",
    "    \n",
    "    finger_print_list.append(curren_polymere.fingerprint())\n",
    "\n",
    "summary_list = list(zip(smile_string_list,finger_print_list,value_list))\n",
    "fp_list_formatted = []\n",
    "for i in finger_print_list:\n",
    "    fp_list_formatted.append(i.tolist())\n",
    "print(len(fp_list_formatted[0]))\n",
    "ss_fp_egc_df = pd.DataFrame({'Smile': smile_string_list, 'Finger_prints': fp_list_formatted, 'Egc': value_list})\n",
    "print(ss_fp_egc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,     9,\n",
      "       ...\n",
      "        2039,  2040,  2041,  2042,  2043,  2044,  2045,  2046,  2047, 'Egc'],\n",
      "      dtype='object', length=2049)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "final_df = pd.DataFrame(\n",
    "    np.array(finger_print_list), index=smile_string_list\n",
    ")\n",
    "\n",
    "ss = pd.Series(value_list, index=smile_string_list, name=\"Egc\")\n",
    "\n",
    "concatenated_df = pd.concat(\n",
    "    [final_df, ss],\n",
    "    axis=1,\n",
    ").reset_index(names=\"psmiles\")\n",
    "print(concatenated_df.set_index(\"psmiles\").columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3380, 2050)\n",
      "(3380, 2049)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>Egc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.6991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.9694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.7012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.3739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8  9  ...  2039  2040  2041  2042  2043  2044  \\\n",
       "2704  0  1  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "2705  0  0  0  0  0  0  0  0  0  4  ...     0     0     0     0     0     0   \n",
       "2706  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "2707  0  0  0  0  0  0  0  0  0  4  ...     0     0     0     0     0     0   \n",
       "2708  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "\n",
       "      2045  2046  2047     Egc  \n",
       "2704     0     0     0  5.0497  \n",
       "2705     0     0     0  5.6991  \n",
       "2706     0     0     0  2.9694  \n",
       "2707     0     0     0  5.7012  \n",
       "2708     0     0     0  5.3739  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "auto_ml_df = concatenated_df.sample(frac=1, random_state=0)#shulles the df\n",
    "print(auto_ml_df.shape)\n",
    "\n",
    "\n",
    "psmlies_column = auto_ml_df[\"psmiles\"]\n",
    "auto_ml_df = auto_ml_df.drop(columns=[\"psmiles\"])\n",
    "auto_ml_df.reset_index(drop=True, inplace=True)\n",
    "print(auto_ml_df.shape)\n",
    "split_index = int(len(auto_ml_df) * 0.8)\n",
    "\n",
    "train_df = auto_ml_df[:split_index]\n",
    "test_df = auto_ml_df[split_index:]\n",
    "# evtl min max scaler \n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X_train = train_df.to_numpy()[:, :-1]\n",
    "y_train = train_df.to_numpy()[:, -1]\n",
    "\n",
    "X_test = test_df.to_numpy()[:, :-1] \n",
    "y_test = test_df.to_numpy()[:, -1]\n",
    "\n",
    "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)\n",
    "print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 13:52:23.531333: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 13:52:24.131148: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from autokeras import StructuredDataRegressor\n",
    "\n",
    "\n",
    "ak = StructuredDataRegressor(max_trials=10,loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #9\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "True              |True              |structured_data_block_1/normalize\n",
      "False             |False             |structured_data_block_1/dense_block_1/use_batchnorm\n",
      "2                 |2                 |structured_data_block_1/dense_block_1/num_layers\n",
      "32                |128               |structured_data_block_1/dense_block_1/units_0\n",
      "0.25              |0                 |structured_data_block_1/dense_block_1/dropout\n",
      "1024              |32                |structured_data_block_1/dense_block_1/units_1\n",
      "0                 |0                 |regression_head_1/dropout\n",
      "adam              |adam              |optimizer\n",
      "1e-05             |0.001             |learning_rate\n",
      "128               |None              |structured_data_block_1/dense_block_1/units_2\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ibrahim/Ibrahim_Python_Scripts/AutoKerasTest.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgaladriel.ing.uni-bayreuth.de/home/ibrahim/Ibrahim_Python_Scripts/AutoKerasTest.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m ak\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mX_train,y\u001b[39m=\u001b[39;49my_train,epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/autokeras/tasks/structured_data.py:139\u001b[0m, in \u001b[0;36mBaseStructuredDataPipeline.fit\u001b[0;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         validation_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_from_csv(x_val, y_val)\n\u001b[1;32m    137\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_in_fit(x)\n\u001b[0;32m--> 139\u001b[0m history \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    140\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    141\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    142\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    143\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    144\u001b[0m     validation_split\u001b[39m=\u001b[39;49mvalidation_split,\n\u001b[1;32m    145\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m    146\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    147\u001b[0m )\n\u001b[1;32m    148\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/autokeras/auto_model.py:292\u001b[0m, in \u001b[0;36mAutoModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mif\u001b[39;00m validation_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m validation_split:\n\u001b[1;32m    288\u001b[0m     dataset, validation_data \u001b[39m=\u001b[39m data_utils\u001b[39m.\u001b[39msplit_dataset(\n\u001b[1;32m    289\u001b[0m         dataset, validation_split\n\u001b[1;32m    290\u001b[0m     )\n\u001b[0;32m--> 292\u001b[0m history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtuner\u001b[39m.\u001b[39;49msearch(\n\u001b[1;32m    293\u001b[0m     x\u001b[39m=\u001b[39;49mdataset,\n\u001b[1;32m    294\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    295\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    296\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m    297\u001b[0m     validation_split\u001b[39m=\u001b[39;49mvalidation_split,\n\u001b[1;32m    298\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    299\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    300\u001b[0m )\n\u001b[1;32m    302\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/autokeras/engine/tuner.py:193\u001b[0m, in \u001b[0;36mAutoTuner.search\u001b[0;34m(self, epochs, callbacks, validation_split, verbose, **fit_kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[1;32m    192\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mupdate_space(hp)\n\u001b[0;32m--> 193\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msearch(\n\u001b[1;32m    194\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs, callbacks\u001b[39m=\u001b[39;49mnew_callbacks, verbose\u001b[39m=\u001b[39;49mverbose, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs\n\u001b[1;32m    195\u001b[0m )\n\u001b[1;32m    197\u001b[0m \u001b[39m# Train the best model use validation data.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# Train the best model with enough number of epochs.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m validation_split \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m early_stopping_inserted:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:230\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 230\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    231\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    232\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:270\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m    269\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 270\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    271\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[1;32m    272\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 235\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    236\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[1;32m    237\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[1;32m    238\u001b[0m     ):\n\u001b[1;32m    239\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    240\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    241\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    243\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    250\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    251\u001b[0m         )\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/keras_tuner/engine/tuner.py:287\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    286\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> 287\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    289\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[1;32m    290\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/autokeras/engine/tuner.py:91\u001b[0m, in \u001b[0;36mAutoTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_build_and_fit_model\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 91\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_build(trial\u001b[39m.\u001b[39;49mhyperparameters)\n\u001b[1;32m     92\u001b[0m     (\n\u001b[1;32m     93\u001b[0m         pipeline,\n\u001b[1;32m     94\u001b[0m         kwargs[\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     95\u001b[0m         kwargs[\u001b[39m\"\u001b[39m\u001b[39mvalidation_data\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     96\u001b[0m     ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_model_build(trial\u001b[39m.\u001b[39mhyperparameters, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     97\u001b[0m     pipeline\u001b[39m.\u001b[39msave(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline_path(trial\u001b[39m.\u001b[39mtrial_id))\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/keras_tuner/engine/tuner.py:155\u001b[0m, in \u001b[0;36mTuner._try_build\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    152\u001b[0m keras\u001b[39m.\u001b[39mbackend\u001b[39m.\u001b[39mclear_session()\n\u001b[1;32m    153\u001b[0m gc\u001b[39m.\u001b[39mcollect()\n\u001b[0;32m--> 155\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_hypermodel(hp)\n\u001b[1;32m    156\u001b[0m \u001b[39m# Stop if `build()` does not return a valid model.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(model, keras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mModel):\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/keras_tuner/engine/tuner.py:146\u001b[0m, in \u001b[0;36mTuner._build_hypermodel\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_build_hypermodel\u001b[39m(\u001b[39mself\u001b[39m, hp):\n\u001b[1;32m    145\u001b[0m     \u001b[39mwith\u001b[39;00m maybe_distribute(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribution_strategy):\n\u001b[0;32m--> 146\u001b[0m         model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mbuild(hp)\n\u001b[1;32m    147\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_override_compile_args(model)\n\u001b[1;32m    148\u001b[0m         \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/keras_tuner/engine/hypermodel.py:115\u001b[0m, in \u001b[0;36mHyperModel._build_wrapper\u001b[0;34m(self, hp, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtunable:\n\u001b[1;32m    112\u001b[0m     \u001b[39m# Copy `HyperParameters` object so that new entries are not added\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[39m# to the search space.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     hp \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m--> 115\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build(hp, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/autokeras/graph.py:250\u001b[0m, in \u001b[0;36mGraph.build\u001b[0;34m(self, hp)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[1;32m    246\u001b[0m     temp_inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m    247\u001b[0m         keras_nodes[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_node_to_id[input_node]]\n\u001b[1;32m    248\u001b[0m         \u001b[39mfor\u001b[39;00m input_node \u001b[39min\u001b[39;00m block\u001b[39m.\u001b[39minputs\n\u001b[1;32m    249\u001b[0m     ]\n\u001b[0;32m--> 250\u001b[0m     outputs \u001b[39m=\u001b[39m block\u001b[39m.\u001b[39;49mbuild(hp, inputs\u001b[39m=\u001b[39;49mtemp_inputs)\n\u001b[1;32m    251\u001b[0m     outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mflatten(outputs)\n\u001b[1;32m    252\u001b[0m     \u001b[39mfor\u001b[39;00m output_node, real_output_node \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(block\u001b[39m.\u001b[39moutputs, outputs):\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/autokeras/engine/block.py:38\u001b[0m, in \u001b[0;36mBlock._build_wrapper\u001b[0;34m(self, hp, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_build_wrapper\u001b[39m(\u001b[39mself\u001b[39m, hp, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     37\u001b[0m     \u001b[39mwith\u001b[39;00m hp\u001b[39m.\u001b[39mname_scope(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname):\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_build_wrapper(hp, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/keras_tuner/engine/hypermodel.py:115\u001b[0m, in \u001b[0;36mHyperModel._build_wrapper\u001b[0;34m(self, hp, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtunable:\n\u001b[1;32m    112\u001b[0m     \u001b[39m# Copy `HyperParameters` object so that new entries are not added\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[39m# to the search space.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     hp \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m--> 115\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build(hp, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/autokeras/blocks/wrapper.py:249\u001b[0m, in \u001b[0;36mStructuredDataBlock.build\u001b[0;34m(self, hp, inputs)\u001b[0m\n\u001b[1;32m    247\u001b[0m     block\u001b[39m.\u001b[39mcolumn_types \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumn_types\n\u001b[1;32m    248\u001b[0m     block\u001b[39m.\u001b[39mcolumn_names \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumn_names\n\u001b[0;32m--> 249\u001b[0m     output_node \u001b[39m=\u001b[39m block\u001b[39m.\u001b[39;49mbuild(hp, output_node)\n\u001b[1;32m    251\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalize \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m hp\u001b[39m.\u001b[39mBoolean(NORMALIZE):\n\u001b[1;32m    252\u001b[0m     \u001b[39mwith\u001b[39;00m hp\u001b[39m.\u001b[39mconditional_scope(NORMALIZE, [\u001b[39mTrue\u001b[39;00m]):\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/autokeras/engine/block.py:38\u001b[0m, in \u001b[0;36mBlock._build_wrapper\u001b[0;34m(self, hp, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_build_wrapper\u001b[39m(\u001b[39mself\u001b[39m, hp, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     37\u001b[0m     \u001b[39mwith\u001b[39;00m hp\u001b[39m.\u001b[39mname_scope(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname):\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_build_wrapper(hp, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/keras_tuner/engine/hypermodel.py:115\u001b[0m, in \u001b[0;36mHyperModel._build_wrapper\u001b[0;34m(self, hp, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtunable:\n\u001b[1;32m    112\u001b[0m     \u001b[39m# Copy `HyperParameters` object so that new entries are not added\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[39m# to the search space.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     hp \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m--> 115\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build(hp, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/autokeras/blocks/preprocessing.py:325\u001b[0m, in \u001b[0;36mCategoricalToNumerical.build\u001b[0;34m(self, hp, inputs)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m         encoding\u001b[39m.\u001b[39mappend(keras_layers\u001b[39m.\u001b[39mNONE)\n\u001b[0;32m--> 325\u001b[0m \u001b[39mreturn\u001b[39;00m keras_layers\u001b[39m.\u001b[39;49mMultiCategoryEncoding(encoding)(input_node)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/autokeras/keras_layers.py:78\u001b[0m, in \u001b[0;36mMultiCategoryEncoding.__init__\u001b[0;34m(self, encoding, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding_layers\u001b[39m.\u001b[39mappend(\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     74\u001b[0m \u001b[39melif\u001b[39;00m encoding \u001b[39m==\u001b[39m INT:\n\u001b[1;32m     75\u001b[0m     \u001b[39m# Set a temporary vocabulary to prevent the error of no\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[39m# vocabulary when calling the layer to build the model.  The\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[39m# vocabulary would be reset by adapting the layer later.\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding_layers\u001b[39m.\u001b[39mappend(layers\u001b[39m.\u001b[39;49mStringLookup())\n\u001b[1;32m     79\u001b[0m \u001b[39melif\u001b[39;00m encoding \u001b[39m==\u001b[39m ONE_HOT:\n\u001b[1;32m     80\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding_layers\u001b[39m.\u001b[39mappend(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/keras/src/layers/preprocessing/string_lookup.py:334\u001b[0m, in \u001b[0;36mStringLookup.__init__\u001b[0;34m(self, max_tokens, num_oov_indices, mask_token, oov_token, vocabulary, idf_weights, encoding, invert, output_mode, sparse, pad_to_max_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[39mdel\u001b[39;00m kwargs[\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    332\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding \u001b[39m=\u001b[39m encoding\n\u001b[0;32m--> 334\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    335\u001b[0m     max_tokens\u001b[39m=\u001b[39;49mmax_tokens,\n\u001b[1;32m    336\u001b[0m     num_oov_indices\u001b[39m=\u001b[39;49mnum_oov_indices,\n\u001b[1;32m    337\u001b[0m     mask_token\u001b[39m=\u001b[39;49mmask_token,\n\u001b[1;32m    338\u001b[0m     oov_token\u001b[39m=\u001b[39;49moov_token,\n\u001b[1;32m    339\u001b[0m     vocabulary\u001b[39m=\u001b[39;49mvocabulary,\n\u001b[1;32m    340\u001b[0m     vocabulary_dtype\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mstring,\n\u001b[1;32m    341\u001b[0m     idf_weights\u001b[39m=\u001b[39;49midf_weights,\n\u001b[1;32m    342\u001b[0m     invert\u001b[39m=\u001b[39;49minvert,\n\u001b[1;32m    343\u001b[0m     output_mode\u001b[39m=\u001b[39;49moutput_mode,\n\u001b[1;32m    344\u001b[0m     sparse\u001b[39m=\u001b[39;49msparse,\n\u001b[1;32m    345\u001b[0m     pad_to_max_tokens\u001b[39m=\u001b[39;49mpad_to_max_tokens,\n\u001b[1;32m    346\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    347\u001b[0m )\n\u001b[1;32m    348\u001b[0m base_preprocessing_layer\u001b[39m.\u001b[39mkeras_kpl_gauge\u001b[39m.\u001b[39mget_cell(\u001b[39m\"\u001b[39m\u001b[39mStringLookup\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mset(\n\u001b[1;32m    349\u001b[0m     \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    350\u001b[0m )\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/keras/src/layers/preprocessing/index_lookup.py:329\u001b[0m, in \u001b[0;36mIndexLookup.__init__\u001b[0;34m(self, max_tokens, num_oov_indices, mask_token, oov_token, vocabulary_dtype, vocabulary, idf_weights, invert, output_mode, sparse, pad_to_max_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_vocabulary(vocabulary, idf_weights)\n\u001b[1;32m    324\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m     \u001b[39m# When restoring from a keras SavedModel, the loading code will\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[39m# expect to find and restore a lookup_table attribute on the layer.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m     \u001b[39m# This table needs to be uninitialized as a StaticHashTable cannot\u001b[39;00m\n\u001b[1;32m    328\u001b[0m     \u001b[39m# be initialized twice.\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlookup_table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_uninitialized_lookup_table()\n\u001b[1;32m    331\u001b[0m \u001b[39m# Only set up adapt state if we did not receive a vocab on construction.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_input_vocabulary:\n\u001b[1;32m    333\u001b[0m     \u001b[39m# Add custom weight handler to return the layer's vocab as a weight.\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/keras/src/layers/preprocessing/index_lookup.py:869\u001b[0m, in \u001b[0;36mIndexLookup._uninitialized_lookup_table\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39minit_scope():\n\u001b[1;32m    868\u001b[0m     initializer \u001b[39m=\u001b[39m NullInitializer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_key_dtype, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value_dtype)\n\u001b[0;32m--> 869\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mlookup\u001b[39m.\u001b[39;49mStaticHashTable(initializer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_value)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/trackable/resource.py:102\u001b[0m, in \u001b[0;36m_ResourceMetaclass.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mfor\u001b[39;00m getter \u001b[39min\u001b[39;00m resource_creator_stack[\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_resource_type()]:\n\u001b[1;32m    100\u001b[0m   previous_getter \u001b[39m=\u001b[39m _make_getter(getter, previous_getter)\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m previous_getter(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/trackable/resource.py:97\u001b[0m, in \u001b[0;36m_ResourceMetaclass.__call__.<locals>.<lambda>\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     94\u001b[0m   obj\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39ma, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[1;32m     95\u001b[0m   \u001b[39mreturn\u001b[39;00m obj\n\u001b[0;32m---> 97\u001b[0m previous_getter \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39ma, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: default_resource_creator(\u001b[39mNone\u001b[39;49;00m, \u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m     98\u001b[0m resource_creator_stack \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\u001b[39m.\u001b[39m_resource_creator_stack\n\u001b[1;32m     99\u001b[0m \u001b[39mfor\u001b[39;00m getter \u001b[39min\u001b[39;00m resource_creator_stack[\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_resource_type()]:\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/trackable/resource.py:94\u001b[0m, in \u001b[0;36m_ResourceMetaclass.__call__.<locals>.default_resource_creator\u001b[0;34m(next_creator, *a, **kw)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39massert\u001b[39;00m next_creator \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     93\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m*\u001b[39ma, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m---> 94\u001b[0m obj\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m     95\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/ops/lookup_ops.py:347\u001b[0m, in \u001b[0;36mStaticHashTable.__init__\u001b[0;34m(self, initializer, default_value, name, experimental_is_anonymous)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mhash_table\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    346\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_table_name \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[39msuper\u001b[39;49m(StaticHashTable, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(default_value, initializer)\n\u001b[1;32m    348\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value_shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_value\u001b[39m.\u001b[39mget_shape()\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/ops/lookup_ops.py:198\u001b[0m, in \u001b[0;36mInitializableLookupTableBase.__init__\u001b[0;34m(self, default_value, initializer)\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initializer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_track_trackable(initializer, \u001b[39m\"\u001b[39m\u001b[39m_initializer\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    197\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39minit_scope():\n\u001b[0;32m--> 198\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_resource_handle \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_resource()\n\u001b[1;32m    199\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mand\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     ops\u001b[39m.\u001b[39mget_default_graph()\u001b[39m.\u001b[39m_get_control_flow_context() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    201\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39minit_scope():\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/ops/lookup_ops.py:357\u001b[0m, in \u001b[0;36mStaticHashTable._create_resource\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m   table_ref \u001b[39m=\u001b[39m gen_lookup_ops\u001b[39m.\u001b[39manonymous_hash_table(\n\u001b[1;32m    353\u001b[0m       key_dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initializer\u001b[39m.\u001b[39mkey_dtype,\n\u001b[1;32m    354\u001b[0m       value_dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initializer\u001b[39m.\u001b[39mvalue_dtype,\n\u001b[1;32m    355\u001b[0m       name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name)\n\u001b[1;32m    356\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 357\u001b[0m   table_ref \u001b[39m=\u001b[39m gen_lookup_ops\u001b[39m.\u001b[39;49mhash_table_v2(\n\u001b[1;32m    358\u001b[0m       shared_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shared_name,\n\u001b[1;32m    359\u001b[0m       key_dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initializer\u001b[39m.\u001b[39;49mkey_dtype,\n\u001b[1;32m    360\u001b[0m       value_dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initializer\u001b[39m.\u001b[39;49mvalue_dtype,\n\u001b[1;32m    361\u001b[0m       name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name)\n\u001b[1;32m    362\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m    363\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_table_name \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/ops/gen_lookup_ops.py:470\u001b[0m, in \u001b[0;36mhash_table_v2\u001b[0;34m(key_dtype, value_dtype, container, shared_name, use_node_name_sharing, name)\u001b[0m\n\u001b[1;32m    468\u001b[0m   \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 470\u001b[0m   \u001b[39mreturn\u001b[39;00m hash_table_v2_eager_fallback(\n\u001b[1;32m    471\u001b[0m       container\u001b[39m=\u001b[39;49mcontainer, shared_name\u001b[39m=\u001b[39;49mshared_name,\n\u001b[1;32m    472\u001b[0m       use_node_name_sharing\u001b[39m=\u001b[39;49muse_node_name_sharing, key_dtype\u001b[39m=\u001b[39;49mkey_dtype,\n\u001b[1;32m    473\u001b[0m       value_dtype\u001b[39m=\u001b[39;49mvalue_dtype, name\u001b[39m=\u001b[39;49mname, ctx\u001b[39m=\u001b[39;49m_ctx)\n\u001b[1;32m    474\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_SymbolicException:\n\u001b[1;32m    475\u001b[0m   \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/ops/gen_lookup_ops.py:524\u001b[0m, in \u001b[0;36mhash_table_v2_eager_fallback\u001b[0;34m(key_dtype, value_dtype, container, shared_name, use_node_name_sharing, name, ctx)\u001b[0m\n\u001b[1;32m    520\u001b[0m _inputs_flat \u001b[39m=\u001b[39m []\n\u001b[1;32m    521\u001b[0m _attrs \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mcontainer\u001b[39m\u001b[39m\"\u001b[39m, container, \u001b[39m\"\u001b[39m\u001b[39mshared_name\u001b[39m\u001b[39m\"\u001b[39m, shared_name,\n\u001b[1;32m    522\u001b[0m \u001b[39m\"\u001b[39m\u001b[39muse_node_name_sharing\u001b[39m\u001b[39m\"\u001b[39m, use_node_name_sharing, \u001b[39m\"\u001b[39m\u001b[39mkey_dtype\u001b[39m\u001b[39m\"\u001b[39m, key_dtype,\n\u001b[1;32m    523\u001b[0m \u001b[39m\"\u001b[39m\u001b[39mvalue_dtype\u001b[39m\u001b[39m\"\u001b[39m, value_dtype)\n\u001b[0;32m--> 524\u001b[0m _result \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39;49mexecute(\u001b[39mb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mHashTableV2\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m1\u001b[39;49m, inputs\u001b[39m=\u001b[39;49m_inputs_flat,\n\u001b[1;32m    525\u001b[0m                            attrs\u001b[39m=\u001b[39;49m_attrs, ctx\u001b[39m=\u001b[39;49mctx, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m    526\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n\u001b[1;32m    527\u001b[0m   _execute\u001b[39m.\u001b[39mrecord_gradient(\n\u001b[1;32m    528\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mHashTableV2\u001b[39m\u001b[39m\"\u001b[39m, _inputs_flat, _attrs, _result)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ak.fit(x=X_train,y=y_train,epochs=1000,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2048)]            0         \n",
      "                                                                 \n",
      " multi_category_encoding (M  (None, 2048)              0         \n",
      " ultiCategoryEncoding)                                           \n",
      "                                                                 \n",
      " normalization (Normalizati  (None, 2048)              4097      \n",
      " on)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                65568     \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " regression_head_1 (Dense)   (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70754 (276.39 KB)\n",
      "Trainable params: 66657 (260.38 KB)\n",
      "Non-trainable params: 4097 (16.01 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = ak.export_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 15s 195ms/step\n",
      "22/22 [==============================] - 4s 199ms/step\n",
      "85/85 [==============================] - 27s 191ms/step\n",
      "85/85 [==============================] - 16s 191ms/step\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ihre vorhergesagten Werte fÃ¼r Trainings- und Testdaten\n",
    "train_predictions = ak.predict(X_train)\n",
    "test_predictions = ak.predict(X_test)\n",
    "\n",
    "# Die echten Werte fÃ¼r Trainings- und Testdaten\n",
    "real_train = y_train\n",
    "real_test = y_test\n",
    "\"\"\"\n",
    "# Plotten der Daten\n",
    "plt.scatter(train_predictions, real_train, label=\"Trainingsdaten\", c=\"#d95f02\", alpha=0.5)\n",
    "plt.scatter(test_predictions, real_test, label=\"Testdaten\", c=\"#7570b3\", alpha=0.5)\n",
    "\n",
    "plt.xlabel(\"Vorhergesagter Wert\")\n",
    "plt.ylabel(\"Echter Wert\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 fÃ¼r Testdaten: 0.4867586151862874\n",
      "MAE fÃ¼r Testdaten: 0.7920412251729937\n",
      "mse_test: 1.2184295541834265\n",
      "R2 fÃ¼r Trainingsdaten: 0.9445100313213182\n",
      "MAE fÃ¼r Trainingsdaten: 0.231219265700815\n",
      "mse_train: 0.13648657608382353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error , mean_squared_error\n",
    "\n",
    "# Berechne R2 fÃ¼r Testdaten\n",
    "r2_test = r2_score(real_test, test_predictions)\n",
    "print(\"R2 fÃ¼r Testdaten:\", r2_test)\n",
    "\n",
    "# Berechne MAE fÃ¼r Testdaten\n",
    "mae_test = mean_absolute_error(real_test, test_predictions)\n",
    "print(\"MAE fÃ¼r Testdaten:\", mae_test)\n",
    "\n",
    "mse_test = mean_squared_error(real_test, test_predictions)\n",
    "print(\"mse_test:\", mse_test)\n",
    "\n",
    "# Berechne R2 fÃ¼r Trainingsdaten\n",
    "r2_train = r2_score(real_train, train_predictions)\n",
    "print(\"R2 fÃ¼r Trainingsdaten:\", r2_train)\n",
    "\n",
    "# Berechne MAE fÃ¼r Trainingsdaten\n",
    "mae_train = mean_absolute_error(real_train, train_predictions)\n",
    "print(\"MAE fÃ¼r Trainingsdaten:\", mae_train)\n",
    "\n",
    "mse_train = mean_squared_error(real_train, train_predictions)\n",
    "print(\"mse_train:\", mse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.save(\"/home/ibrahim/models/SDRTEST\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
