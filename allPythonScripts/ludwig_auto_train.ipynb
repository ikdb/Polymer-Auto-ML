{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "                                                 Smile  \\\n",
      "0                                              [*]C[*]   \n",
      "1                                          [*]CC([*])C   \n",
      "2                                         [*]CC([*])CC   \n",
      "3                                        [*]CC([*])CCC   \n",
      "4                                     [*]CC([*])CC(C)C   \n",
      "...                                                ...   \n",
      "3375           [*]Nc1c([2H])c([2H])c([*])c([2H])c1[2H]   \n",
      "3376               [*]CCCCCC[N+](C)(C)CCC[N+]([*])(C)C   \n",
      "3377          [*]CCCCCCCC[N+](C)(C)CCCCCC[N+]([*])(C)C   \n",
      "3378  [*]CCCCCCCCCCCCCCCC[N+](C)(C)CCCCCC[N+]([*])(C)C   \n",
      "3379       [*]C=Cc1cc([Si](C)(C)C)c([*])cc1[Si](C)(C)C   \n",
      "\n",
      "                                          Finger_prints     Egc  \n",
      "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  6.8972  \n",
      "1     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  6.5196  \n",
      "2     [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  6.5170  \n",
      "3     [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  6.7336  \n",
      "4     [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  6.7394  \n",
      "...                                                 ...     ...  \n",
      "3375  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  3.3666  \n",
      "3376  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.2161  \n",
      "3377  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.1032  \n",
      "3378  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  0.1771  \n",
      "3379  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  2.2084  \n",
      "\n",
      "[3380 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from psmiles import PolymerSmiles as PS\n",
    "import pandas as pd\n",
    "# Read csv and filter EGC\n",
    "egc_df = pd.read_csv(\"/home/ibrahim/recources/export.csv\")\n",
    "egc_df = egc_df[egc_df.property == \"Egc\"]\n",
    "\n",
    "#creating fingerprints for SS\n",
    "smile_string_list = list(egc_df.smiles.values)\n",
    "value_list = list(egc_df.value.values)\n",
    "finger_print_list = []\n",
    "for ss in smile_string_list:\n",
    "    curren_polymere = PS(ss)\n",
    "    \n",
    "    \n",
    "    finger_print_list.append(curren_polymere.fingerprint())\n",
    "\n",
    "summary_list = list(zip(smile_string_list,finger_print_list,value_list))\n",
    "fp_list_formatted = []\n",
    "for i in finger_print_list:\n",
    "    fp_list_formatted.append(i.tolist())\n",
    "print(len(fp_list_formatted[0]))\n",
    "ss_fp_egc_df = pd.DataFrame({'Smile': smile_string_list, 'Finger_prints': fp_list_formatted, 'Egc': value_list})\n",
    "print(ss_fp_egc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,     9,\n",
      "       ...\n",
      "        2039,  2040,  2041,  2042,  2043,  2044,  2045,  2046,  2047, 'Egc'],\n",
      "      dtype='object', length=2049)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "final_df = pd.DataFrame(\n",
    "    np.array(finger_print_list), index=smile_string_list\n",
    ")\n",
    "\n",
    "ss = pd.Series(value_list, index=smile_string_list, name=\"Egc\")\n",
    "\n",
    "concatenated_df = pd.concat(\n",
    "    [final_df, ss],\n",
    "    axis=1,\n",
    ").reset_index(names=\"psmiles\")\n",
    "print(concatenated_df.set_index(\"psmiles\").columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3380, 2050)\n",
      "(3380, 2049)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>Egc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.6991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.9694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.7012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.3739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5  6  7  8  9  ...  2039  2040  2041  2042  2043  2044  \\\n",
       "2704  0  1  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "2705  0  0  0  0  0  0  0  0  0  4  ...     0     0     0     0     0     0   \n",
       "2706  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "2707  0  0  0  0  0  0  0  0  0  4  ...     0     0     0     0     0     0   \n",
       "2708  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "\n",
       "      2045  2046  2047     Egc  \n",
       "2704     0     0     0  5.0497  \n",
       "2705     0     0     0  5.6991  \n",
       "2706     0     0     0  2.9694  \n",
       "2707     0     0     0  5.7012  \n",
       "2708     0     0     0  5.3739  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "auto_ml_df = concatenated_df.sample(frac=1, random_state=0)#shulles the df\n",
    "print(auto_ml_df.shape)\n",
    "\n",
    "\n",
    "psmlies_column = auto_ml_df[\"psmiles\"]\n",
    "auto_ml_df = auto_ml_df.drop(columns=[\"psmiles\"])\n",
    "auto_ml_df.reset_index(drop=True, inplace=True)\n",
    "print(auto_ml_df.shape)\n",
    "split_index = int(len(auto_ml_df) * 0.8)\n",
    "\n",
    "train_df = auto_ml_df[:split_index]\n",
    "test_df = auto_ml_df[split_index:]\n",
    "# evtl min max scaler \n",
    "train_df.columns = train_df.columns.astype(str)\n",
    "test_df.columns = test_df.columns.astype(str)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((2704, 2048), (2704,)), ((676, 2048), (676,)))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train_df.to_numpy()[:, :-1]\n",
    "y_train = train_df.to_numpy()[:, -1]\n",
    "\n",
    "X_test = test_df.to_numpy()[:, :-1] \n",
    "y_test = test_df.to_numpy()[:, -1]\n",
    "\n",
    "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gputil in /home/ibrahim/.venv/lib/python3.10/site-packages (1.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gputil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing fields: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2049/2049 [00:00<00:00, 2068.31it/s]\n",
      "/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/schema/model_types/utils.py:238: UserWarning: Can't utilize `early_stop` while using a hyperopt scheduler. Setting early stop to -1.\n",
      "  warnings.warn(\"Can't utilize `early_stop` while using a hyperopt scheduler. Setting early stop to -1.\")\n",
      "/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/utils.py:204: RuntimeWarning: All hyperopt parameters in Ludwig config are using grid_search space, but number of samples (10) is greater than 1. This will result in 9 duplicate trials being created. Consider setting `num_samples` to 1 in the hyperopt executor to prevent trial duplication.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-11-07 16:00:54</td></tr>\n",
       "<tr><td>Running for: </td><td>00:05:48.41        </td></tr>\n",
       "<tr><td>Memory:      </td><td>40.8/1007.5 GiB    </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 9000.000: None | Iter 1800.000: None | Iter 360.000: None | Iter 72.000: None<br>Resources requested: 0/192 CPUs, 0/4 GPUs, 0.0/789.43 GiB heap, 0.0/186.26 GiB objects (0.0/1.0 accelerator_type:A100)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 10<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                            </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trial_d904e610</td><td style=\"text-align: right;\">           1</td><td>/home/ibrahim/Ibrahim_Python_Scripts/hyperopt/trial_d904e610/error.txt</td></tr>\n",
       "<tr><td>trial_1963d626</td><td style=\"text-align: right;\">           1</td><td>/home/ibrahim/Ibrahim_Python_Scripts/hyperopt/trial_1963d626/error.txt</td></tr>\n",
       "<tr><td>trial_48cee7b7</td><td style=\"text-align: right;\">           1</td><td>/home/ibrahim/Ibrahim_Python_Scripts/hyperopt/trial_48cee7b7/error.txt</td></tr>\n",
       "<tr><td>trial_d071270d</td><td style=\"text-align: right;\">           1</td><td>/home/ibrahim/Ibrahim_Python_Scripts/hyperopt/trial_d071270d/error.txt</td></tr>\n",
       "<tr><td>trial_0fdfa967</td><td style=\"text-align: right;\">           1</td><td>/home/ibrahim/Ibrahim_Python_Scripts/hyperopt/trial_0fdfa967/error.txt</td></tr>\n",
       "<tr><td>trial_2458c9cc</td><td style=\"text-align: right;\">           1</td><td>/home/ibrahim/Ibrahim_Python_Scripts/hyperopt/trial_2458c9cc/error.txt</td></tr>\n",
       "<tr><td>trial_68ef7ee7</td><td style=\"text-align: right;\">           1</td><td>/home/ibrahim/Ibrahim_Python_Scripts/hyperopt/trial_68ef7ee7/error.txt</td></tr>\n",
       "<tr><td>trial_1332a628</td><td style=\"text-align: right;\">           1</td><td>/home/ibrahim/Ibrahim_Python_Scripts/hyperopt/trial_1332a628/error.txt</td></tr>\n",
       "<tr><td>trial_e2b8ce46</td><td style=\"text-align: right;\">           1</td><td>/home/ibrahim/Ibrahim_Python_Scripts/hyperopt/trial_e2b8ce46/error.txt</td></tr>\n",
       "<tr><td>trial_a28c7019</td><td style=\"text-align: right;\">           1</td><td>/home/ibrahim/Ibrahim_Python_Scripts/hyperopt/trial_a28c7019/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status  </th><th>loc                  </th><th style=\"text-align: right;\">  combiner.bn_momentum</th><th style=\"text-align: right;\">     combiner.bn_virtual_\n",
       "bs</th><th style=\"text-align: right;\">  combiner.num_steps</th><th style=\"text-align: right;\">  combiner.output_size</th><th style=\"text-align: right;\">    combiner.relaxation_\n",
       "factor</th><th style=\"text-align: right;\">  combiner.size</th><th style=\"text-align: right;\">  combiner.sparsity</th><th style=\"text-align: right;\">            trainer.learning_rat\n",
       "e</th><th style=\"text-align: right;\">     ...er.learning_rate_\n",
       "scheduler.decay_rate</th><th style=\"text-align: right;\">      ...r.learning_rate_s\n",
       "cheduler.decay_steps</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trial_d904e610</td><td>ERROR   </td><td>132.180.187.66:142287</td><td style=\"text-align: right;\">                  0.3 </td><td style=\"text-align: right;\">2048</td><td style=\"text-align: right;\">                   4</td><td style=\"text-align: right;\">                     8</td><td style=\"text-align: right;\">1  </td><td style=\"text-align: right;\">             32</td><td style=\"text-align: right;\">             0.0001</td><td style=\"text-align: right;\">0.000799724</td><td style=\"text-align: right;\">0.8 </td><td style=\"text-align: right;\">20000</td></tr>\n",
       "<tr><td>trial_1963d626</td><td>ERROR   </td><td>132.180.187.66:144411</td><td style=\"text-align: right;\">                  0.2 </td><td style=\"text-align: right;\"> 256</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">                   128</td><td style=\"text-align: right;\">1  </td><td style=\"text-align: right;\">             32</td><td style=\"text-align: right;\">             0     </td><td style=\"text-align: right;\">0.000174588</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">  500</td></tr>\n",
       "<tr><td>trial_48cee7b7</td><td>ERROR   </td><td>132.180.187.66:146386</td><td style=\"text-align: right;\">                  0.02</td><td style=\"text-align: right;\">1024</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                     8</td><td style=\"text-align: right;\">1  </td><td style=\"text-align: right;\">              8</td><td style=\"text-align: right;\">             1e-06 </td><td style=\"text-align: right;\">0.000140605</td><td style=\"text-align: right;\">0.8 </td><td style=\"text-align: right;\">  500</td></tr>\n",
       "<tr><td>trial_d071270d</td><td>ERROR   </td><td>132.180.187.66:148358</td><td style=\"text-align: right;\">                  0.2 </td><td style=\"text-align: right;\">1024</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                    24</td><td style=\"text-align: right;\">2  </td><td style=\"text-align: right;\">              8</td><td style=\"text-align: right;\">             0.001 </td><td style=\"text-align: right;\">3.67484e-05</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\"> 2000</td></tr>\n",
       "<tr><td>trial_0fdfa967</td><td>ERROR   </td><td>132.180.187.66:163950</td><td style=\"text-align: right;\">                  0.1 </td><td style=\"text-align: right;\"> 256</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">                    64</td><td style=\"text-align: right;\">1.5</td><td style=\"text-align: right;\">             64</td><td style=\"text-align: right;\">             0.0001</td><td style=\"text-align: right;\">6.27954e-05</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\">  500</td></tr>\n",
       "<tr><td>trial_2458c9cc</td><td>ERROR   </td><td>132.180.187.66:166268</td><td style=\"text-align: right;\">                  0.4 </td><td style=\"text-align: right;\"> 256</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                    16</td><td style=\"text-align: right;\">1.2</td><td style=\"text-align: right;\">             16</td><td style=\"text-align: right;\">             0.01  </td><td style=\"text-align: right;\">0.000120926</td><td style=\"text-align: right;\">0.9 </td><td style=\"text-align: right;\">  500</td></tr>\n",
       "<tr><td>trial_68ef7ee7</td><td>ERROR   </td><td>132.180.187.66:168511</td><td style=\"text-align: right;\">                  0.4 </td><td style=\"text-align: right;\"> 512</td><td style=\"text-align: right;\">                   5</td><td style=\"text-align: right;\">                    32</td><td style=\"text-align: right;\">2  </td><td style=\"text-align: right;\">              8</td><td style=\"text-align: right;\">             0     </td><td style=\"text-align: right;\">0.00014451 </td><td style=\"text-align: right;\">0.9 </td><td style=\"text-align: right;\">10000</td></tr>\n",
       "<tr><td>trial_1332a628</td><td>ERROR   </td><td>132.180.187.66:170635</td><td style=\"text-align: right;\">                  0.1 </td><td style=\"text-align: right;\">4096</td><td style=\"text-align: right;\">                   7</td><td style=\"text-align: right;\">                    24</td><td style=\"text-align: right;\">1.5</td><td style=\"text-align: right;\">             64</td><td style=\"text-align: right;\">             0     </td><td style=\"text-align: right;\">3.27468e-05</td><td style=\"text-align: right;\">0.95</td><td style=\"text-align: right;\"> 8000</td></tr>\n",
       "<tr><td>trial_e2b8ce46</td><td>ERROR   </td><td>132.180.187.66:185932</td><td style=\"text-align: right;\">                  0.2 </td><td style=\"text-align: right;\"> 256</td><td style=\"text-align: right;\">                   3</td><td style=\"text-align: right;\">                    16</td><td style=\"text-align: right;\">1.2</td><td style=\"text-align: right;\">             64</td><td style=\"text-align: right;\">             0.001 </td><td style=\"text-align: right;\">0.0003595  </td><td style=\"text-align: right;\">0.8 </td><td style=\"text-align: right;\">  500</td></tr>\n",
       "<tr><td>trial_a28c7019</td><td>ERROR   </td><td>132.180.187.66:188366</td><td style=\"text-align: right;\">                  0.2 </td><td style=\"text-align: right;\"> 512</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">                    16</td><td style=\"text-align: right;\">1  </td><td style=\"text-align: right;\">             24</td><td style=\"text-align: right;\">             0.001 </td><td style=\"text-align: right;\">2.19031e-05</td><td style=\"text-align: right;\">0.9 </td><td style=\"text-align: right;\">10000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=142287)\u001b[0m Created a temporary directory at /tmp/tmpkkbqd8qs\n",
      "\u001b[2m\u001b[36m(pid=142287)\u001b[0m Writing /tmp/tmpkkbqd8qs/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=142287)\u001b[0m 2023-11-07 15:55:10.882449: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(pid=142287)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(pid=142287)\u001b[0m 2023-11-07 15:55:11.535116: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:55:16,299\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=144411)\u001b[0m Created a temporary directory at /tmp/tmp6b_j1qet\n",
      "\u001b[2m\u001b[36m(pid=144411)\u001b[0m Writing /tmp/tmp6b_j1qet/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=144411)\u001b[0m 2023-11-07 15:55:20.289201: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(pid=144411)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(pid=144411)\u001b[0m 2023-11-07 15:55:20.901828: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:55:21,391\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:55:25,546\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:55:26,491\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=146386)\u001b[0m Created a temporary directory at /tmp/tmphkxohpgc\n",
      "\u001b[2m\u001b[36m(pid=146386)\u001b[0m Writing /tmp/tmphkxohpgc/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=146386)\u001b[0m 2023-11-07 15:55:29.988342: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(pid=146386)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:55:30,620\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(pid=146386)\u001b[0m 2023-11-07 15:55:30.592061: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:55:31,550\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:55:35,232\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:55:35,699\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:55:36,629\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=148358)\u001b[0m Created a temporary directory at /tmp/tmph650idhg\n",
      "\u001b[2m\u001b[36m(pid=148358)\u001b[0m Writing /tmp/tmph650idhg/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=148358)\u001b[0m 2023-11-07 15:55:39.246663: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(pid=148358)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(pid=148358)\u001b[0m 2023-11-07 15:55:39.948067: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:55:40,304\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:55:40,771\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:55:41,723\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:55:44,791\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:55:45,377\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:55:45,868\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:55:46,801\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:55:49,869\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:55:50,453\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:55:50,943\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:55:51,875\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:55:54,943\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:55:55,527\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:55:56,033\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:55:56,972\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:55:59,995\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:56:00,595\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:56:01,110\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:56:02,063\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:56:05,078\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:56:05,669\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:56:06,186\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:56:07,133\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:56:10,160\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:56:10,765\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:56:11,261\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:56:12,224\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:56:15,229\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:56:15,840\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:56:16,333\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:56:17,299\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:56:20,326\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:56:20,920\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:56:21,430\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:56:22,360\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:56:25,501\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:56:25,994\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:56:26,503\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:56:27,446\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:56:30,600\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:56:31,067\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:56:31,576\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:56:32,520\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:56:35,713\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:56:36,137\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:56:36,632\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:56:37,638\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:56:40,765\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:56:41,642\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:56:41,724\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:56:42,702\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:56:45,817\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:56:46,719\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:56:46,795\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:56:47,773\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:56:50,904\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:56:52,043\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:56:52,041\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=142287)\u001b[0m 2023-11-07 15:56:52,835\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:56:55,962\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:56:57,141\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:56:57,144\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "2023-11-07 15:56:57,936\tERROR trial_runner.py:1062 -- Trial trial_d904e610: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=142287, ip=132.180.187.66, repr=run_experiment_trial)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 782, in run_experiment_trial\n",
      "    return self._run_experiment(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 457, in _run_experiment\n",
      "    wait_for_gpu(gpu_id)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/utils/util.py\", line 556, in wait_for_gpu\n",
      "    raise RuntimeError(\"GPU memory was not freed.\")\n",
      "RuntimeError: GPU memory was not freed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>date               </th><th>experiment_id                   </th><th>hostname  </th><th>node_ip       </th><th style=\"text-align: right;\">   pid</th><th style=\"text-align: right;\">  timestamp</th><th>trial_id  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trial_0fdfa967</td><td>2023-11-07_15-57-08</td><td>690cfbc3fc514188a928d6992892bccf</td><td>galadriel </td><td>132.180.187.66</td><td style=\"text-align: right;\">163950</td><td style=\"text-align: right;\"> 1699369028</td><td>0fdfa967  </td></tr>\n",
       "<tr><td>trial_1332a628</td><td>2023-11-07_15-57-38</td><td>9d703b99979e41b8be728632bdbf4306</td><td>galadriel </td><td>132.180.187.66</td><td style=\"text-align: right;\">170635</td><td style=\"text-align: right;\"> 1699369058</td><td>1332a628  </td></tr>\n",
       "<tr><td>trial_1963d626</td><td>2023-11-07_15-55-25</td><td>e4620a2d46034071a4963104994811a6</td><td>galadriel </td><td>132.180.187.66</td><td style=\"text-align: right;\">144411</td><td style=\"text-align: right;\"> 1699368925</td><td>1963d626  </td></tr>\n",
       "<tr><td>trial_2458c9cc</td><td>2023-11-07_15-57-18</td><td>fdfddbae5ca04ec2b443a090cca8a6d6</td><td>galadriel </td><td>132.180.187.66</td><td style=\"text-align: right;\">166268</td><td style=\"text-align: right;\"> 1699369038</td><td>2458c9cc  </td></tr>\n",
       "<tr><td>trial_48cee7b7</td><td>2023-11-07_15-55-35</td><td>3ac306125e554700ae4c48fb667a412c</td><td>galadriel </td><td>132.180.187.66</td><td style=\"text-align: right;\">146386</td><td style=\"text-align: right;\"> 1699368935</td><td>48cee7b7  </td></tr>\n",
       "<tr><td>trial_68ef7ee7</td><td>2023-11-07_15-57-28</td><td>86101e4ef52f45a2bf211263dbca72df</td><td>galadriel </td><td>132.180.187.66</td><td style=\"text-align: right;\">168511</td><td style=\"text-align: right;\"> 1699369048</td><td>68ef7ee7  </td></tr>\n",
       "<tr><td>trial_a28c7019</td><td>2023-11-07_15-59-11</td><td>d8254a78c79b4d309a694524b0a6df22</td><td>galadriel </td><td>132.180.187.66</td><td style=\"text-align: right;\">188366</td><td style=\"text-align: right;\"> 1699369151</td><td>a28c7019  </td></tr>\n",
       "<tr><td>trial_d071270d</td><td>2023-11-07_15-55-44</td><td>b6438be75cd648e7ba6882f7b08be4fd</td><td>galadriel </td><td>132.180.187.66</td><td style=\"text-align: right;\">148358</td><td style=\"text-align: right;\"> 1699368944</td><td>d071270d  </td></tr>\n",
       "<tr><td>trial_d904e610</td><td>2023-11-07_15-55-16</td><td>dd1802f09ba1414387b0518c9a32c4ef</td><td>galadriel </td><td>132.180.187.66</td><td style=\"text-align: right;\">142287</td><td style=\"text-align: right;\"> 1699368916</td><td>d904e610  </td></tr>\n",
       "<tr><td>trial_e2b8ce46</td><td>2023-11-07_15-59-00</td><td>7645a6d5e7b84863accbf074d23deaae</td><td>galadriel </td><td>132.180.187.66</td><td style=\"text-align: right;\">185932</td><td style=\"text-align: right;\"> 1699369140</td><td>e2b8ce46  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:57:01,019\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=144411)\u001b[0m 2023-11-07 15:57:02,285\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:57:02,285\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163950)\u001b[0m Created a temporary directory at /tmp/tmpa8jc5h3m\n",
      "\u001b[2m\u001b[36m(pid=163950)\u001b[0m Writing /tmp/tmpa8jc5h3m/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=163950)\u001b[0m 2023-11-07 15:57:03.256263: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(pid=163950)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(pid=163950)\u001b[0m 2023-11-07 15:57:03.862336: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:57:06,080\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:57:07,498\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "2023-11-07 15:57:08,471\tERROR trial_runner.py:1062 -- Trial trial_1963d626: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=144411, ip=132.180.187.66, repr=run_experiment_trial)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 782, in run_experiment_trial\n",
      "    return self._run_experiment(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 457, in _run_experiment\n",
      "    wait_for_gpu(gpu_id)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/utils/util.py\", line 556, in wait_for_gpu\n",
      "    raise RuntimeError(\"GPU memory was not freed.\")\n",
      "RuntimeError: GPU memory was not freed.\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:57:08,630\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:57:11,171\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=146386)\u001b[0m 2023-11-07 15:57:12,717\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=166268)\u001b[0m Created a temporary directory at /tmp/tmpbxlbpifz\n",
      "\u001b[2m\u001b[36m(pid=166268)\u001b[0m Writing /tmp/tmpbxlbpifz/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=166268)\u001b[0m 2023-11-07 15:57:13.299683: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(pid=166268)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:57:13,703\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(pid=166268)\u001b[0m 2023-11-07 15:57:13.933851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:57:16,232\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "2023-11-07 15:57:18,520\tERROR trial_runner.py:1062 -- Trial trial_48cee7b7: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=146386, ip=132.180.187.66, repr=run_experiment_trial)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 782, in run_experiment_trial\n",
      "    return self._run_experiment(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 457, in _run_experiment\n",
      "    wait_for_gpu(gpu_id)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/utils/util.py\", line 556, in wait_for_gpu\n",
      "    raise RuntimeError(\"GPU memory was not freed.\")\n",
      "RuntimeError: GPU memory was not freed.\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:57:18,663\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:57:18,758\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=148358)\u001b[0m 2023-11-07 15:57:21,301\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168511)\u001b[0m Created a temporary directory at /tmp/tmpr1ef9c7l\n",
      "\u001b[2m\u001b[36m(pid=168511)\u001b[0m Writing /tmp/tmpr1ef9c7l/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=168511)\u001b[0m 2023-11-07 15:57:23.009268: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(pid=168511)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(pid=168511)\u001b[0m 2023-11-07 15:57:23.598613: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:57:23,741\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:57:23,833\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "2023-11-07 15:57:28,171\tERROR trial_runner.py:1062 -- Trial trial_d071270d: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=148358, ip=132.180.187.66, repr=run_experiment_trial)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 782, in run_experiment_trial\n",
      "    return self._run_experiment(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 457, in _run_experiment\n",
      "    wait_for_gpu(gpu_id)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/utils/util.py\", line 556, in wait_for_gpu\n",
      "    raise RuntimeError(\"GPU memory was not freed.\")\n",
      "RuntimeError: GPU memory was not freed.\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:57:28,309\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:57:28,814\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:57:28,907\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=170635)\u001b[0m Created a temporary directory at /tmp/tmprid7fhox\n",
      "\u001b[2m\u001b[36m(pid=170635)\u001b[0m Writing /tmp/tmprid7fhox/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=170635)\u001b[0m 2023-11-07 15:57:33.130018: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(pid=170635)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:57:33,380\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(pid=170635)\u001b[0m 2023-11-07 15:57:33.808113: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:57:33,905\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:57:33,990\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:57:38,552\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:57:38,639\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:57:39,064\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:57:38,980\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:57:43,621\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:57:43,727\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:57:44,072\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:57:44,144\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:57:48,788\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:57:48,797\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:57:49,216\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:57:49,141\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:57:53,958\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:57:53,965\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:57:54,216\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:57:54,290\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:57:59,055\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:57:59,063\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:57:59,288\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:57:59,365\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:58:04,153\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:58:04,154\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:58:04,355\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:58:04,438\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:58:09,344\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:58:09,337\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:58:09,522\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:58:09,443\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:58:14,446\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:58:14,440\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:58:14,597\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:58:14,517\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:58:19,564\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:58:19,559\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:58:19,592\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:58:19,668\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:58:24,754\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:58:24,748\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:58:24,740\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:58:24,748\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:58:30,062\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:58:30,061\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:58:30,055\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:58:30,055\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:58:35,174\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:58:35,173\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:58:35,164\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:58:35,168\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:58:40,245\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:58:40,265\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:58:40,259\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:58:40,260\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=163950)\u001b[0m 2023-11-07 15:58:45,357\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:58:45,365\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:58:45,403\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:58:45,405\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:58:50,484\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:58:50,462\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:58:50,467\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "2023-11-07 15:58:50,580\tERROR trial_runner.py:1062 -- Trial trial_0fdfa967: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=163950, ip=132.180.187.66, repr=run_experiment_trial)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 782, in run_experiment_trial\n",
      "    return self._run_experiment(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 457, in _run_experiment\n",
      "    wait_for_gpu(gpu_id)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/utils/util.py\", line 556, in wait_for_gpu\n",
      "    raise RuntimeError(\"GPU memory was not freed.\")\n",
      "RuntimeError: GPU memory was not freed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=185932)\u001b[0m Created a temporary directory at /tmp/tmpbpjzi07t\n",
      "\u001b[2m\u001b[36m(pid=185932)\u001b[0m Writing /tmp/tmpbpjzi07t/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=185932)\u001b[0m 2023-11-07 15:58:55.347542: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(pid=185932)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=166268)\u001b[0m 2023-11-07 15:58:55,597\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:58:55,588\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:58:55,598\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(pid=185932)\u001b[0m 2023-11-07 15:58:56.014894: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:59:00,696\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:59:00,702\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 15:59:00,764\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "2023-11-07 15:59:00,798\tERROR trial_runner.py:1062 -- Trial trial_2458c9cc: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=166268, ip=132.180.187.66, repr=run_experiment_trial)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 782, in run_experiment_trial\n",
      "    return self._run_experiment(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 457, in _run_experiment\n",
      "    wait_for_gpu(gpu_id)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/utils/util.py\", line 556, in wait_for_gpu\n",
      "    raise RuntimeError(\"GPU memory was not freed.\")\n",
      "RuntimeError: GPU memory was not freed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=188366)\u001b[0m Created a temporary directory at /tmp/tmpq_5lgkxj\n",
      "\u001b[2m\u001b[36m(pid=188366)\u001b[0m Writing /tmp/tmpq_5lgkxj/_remote_module_non_scriptable.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(run_experiment_trial pid=168511)\u001b[0m 2023-11-07 15:59:05,773\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:59:05,777\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 15:59:05,834\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(pid=188366)\u001b[0m 2023-11-07 15:59:06.067354: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "\u001b[2m\u001b[36m(pid=188366)\u001b[0m To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[2m\u001b[36m(pid=188366)\u001b[0m 2023-11-07 15:59:06.672021: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:59:11,063\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 15:59:11,063\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "2023-11-07 15:59:11,183\tERROR trial_runner.py:1062 -- Trial trial_68ef7ee7: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=168511, ip=132.180.187.66, repr=run_experiment_trial)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 782, in run_experiment_trial\n",
      "    return self._run_experiment(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 457, in _run_experiment\n",
      "    wait_for_gpu(gpu_id)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/utils/util.py\", line 556, in wait_for_gpu\n",
      "    raise RuntimeError(\"GPU memory was not freed.\")\n",
      "RuntimeError: GPU memory was not freed.\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 15:59:11,319\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=170635)\u001b[0m 2023-11-07 15:59:16,173\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 15:59:16,185\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 15:59:16,391\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "2023-11-07 15:59:21,206\tERROR trial_runner.py:1062 -- Trial trial_1332a628: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=170635, ip=132.180.187.66, repr=run_experiment_trial)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 782, in run_experiment_trial\n",
      "    return self._run_experiment(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 457, in _run_experiment\n",
      "    wait_for_gpu(gpu_id)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/utils/util.py\", line 556, in wait_for_gpu\n",
      "    raise RuntimeError(\"GPU memory was not freed.\")\n",
      "RuntimeError: GPU memory was not freed.\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 15:59:21,286\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 15:59:21,465\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 15:59:26,454\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 15:59:26,542\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 15:59:31,594\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 15:59:31,617\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 15:59:36,739\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 15:59:36,740\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 15:59:41,906\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 15:59:41,920\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 15:59:47,152\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 15:59:47,210\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 15:59:52,362\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 15:59:52,510\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 15:59:57,435\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 15:59:57,584\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 16:00:02,528\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 16:00:02,666\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 16:00:07,744\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 16:00:07,737\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 16:00:12,889\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 16:00:12,886\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 16:00:17,997\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 16:00:17,995\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 16:00:23,195\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 16:00:23,191\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 16:00:28,367\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 16:00:28,363\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 16:00:33,574\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 16:00:33,585\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=185932)\u001b[0m 2023-11-07 16:00:38,670\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.327\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 16:00:38,668\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "2023-11-07 16:00:43,758\tERROR trial_runner.py:1062 -- Trial trial_e2b8ce46: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=185932, ip=132.180.187.66, repr=run_experiment_trial)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 782, in run_experiment_trial\n",
      "    return self._run_experiment(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 457, in _run_experiment\n",
      "    wait_for_gpu(gpu_id)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/utils/util.py\", line 556, in wait_for_gpu\n",
      "    raise RuntimeError(\"GPU memory was not freed.\")\n",
      "RuntimeError: GPU memory was not freed.\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 16:00:43,756\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "\u001b[2m\u001b[36m(run_experiment_trial pid=188366)\u001b[0m 2023-11-07 16:00:48,985\tINFO util.py:549 -- Waiting for GPU util to reach 0.01. Util: 0.168\n",
      "2023-11-07 16:00:54,162\tERROR trial_runner.py:1062 -- Trial trial_a28c7019: Error processing event.\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=188366, ip=132.180.187.66, repr=run_experiment_trial)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/trainable.py\", line 368, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 337, in entrypoint\n",
      "    return self._trainable_func(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/function_trainable.py\", line 654, in _trainable_func\n",
      "    output = fn()\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/trainable/util.py\", line 398, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 782, in run_experiment_trial\n",
      "    return self._run_experiment(\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ludwig/hyperopt/execution.py\", line 457, in _run_experiment\n",
      "    wait_for_gpu(gpu_id)\n",
      "  File \"/home/ibrahim/.venv/lib/python3.10/site-packages/ray/tune/utils/util.py\", line 556, in wait_for_gpu\n",
      "    raise RuntimeError(\"GPU memory was not freed.\")\n",
      "RuntimeError: GPU memory was not freed.\n",
      "2023-11-07 16:00:54,176\tERROR tune.py:794 -- Trials did not complete: [trial_d904e610, trial_1963d626, trial_48cee7b7, trial_d071270d, trial_0fdfa967, trial_2458c9cc, trial_68ef7ee7, trial_1332a628, trial_e2b8ce46, trial_a28c7019]\n",
      "2023-11-07 16:00:54,177\tINFO tune.py:798 -- Total run time: 348.43 seconds (348.41 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ludwig.automl.automl.AutoTrainResults object at 0x7fde484ba140>\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pprint\n",
    "\n",
    "\n",
    "from ludwig.automl import auto_train\n",
    "\n",
    "\n",
    "\n",
    "auto_train_results = auto_train(\n",
    "    dataset=train_df,\n",
    "    target='Egc',\n",
    "    time_limit_s=14400,\n",
    "    tune_for_memory=True\n",
    ")\n",
    "\n",
    "pprint.pprint(auto_train_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ludwig.automl.automl.AutoTrainResults object at 0x7fde286a9c00>\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(auto_train_results)\n",
    "#predictions = auto_train_results.predict(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-07 15:52:08,890\tWARNING experiment_analysis.py:621 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No best trial found. Please check if you specified the correct default metric (metric_score) and mode (min).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ibrahim/Ibrahim_Python_Scripts/ludwig_auto_train.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgaladriel.ing.uni-bayreuth.de/home/ibrahim/Ibrahim_Python_Scripts/ludwig_auto_train.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m auto_train_results\u001b[39m.\u001b[39;49mbest_model\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgaladriel.ing.uni-bayreuth.de/home/ibrahim/Ibrahim_Python_Scripts/ludwig_auto_train.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m best_model \u001b[39m=\u001b[39m auto_train_results\u001b[39m.\u001b[39mbest_model()\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/ludwig/automl/automl.py:94\u001b[0m, in \u001b[0;36mAutoTrainResults.best_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbest_model\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[LudwigModel]:\n\u001b[0;32m---> 94\u001b[0m     checkpoint \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_experiment_analysis\u001b[39m.\u001b[39;49mbest_checkpoint\n\u001b[1;32m     95\u001b[0m     \u001b[39mif\u001b[39;00m checkpoint \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m         logger\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mNo best model found\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/ray/tune/analysis/experiment_analysis.py:249\u001b[0m, in \u001b[0;36mExperimentAnalysis.best_checkpoint\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m best_trial \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_trial\n\u001b[1;32m    248\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m best_trial:\n\u001b[0;32m--> 249\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    250\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo best trial found. Please check if you specified the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcorrect default metric (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_metric\u001b[39m}\u001b[39;00m\u001b[39m) and mode \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_mode\u001b[39m}\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m     )\n\u001b[1;32m    254\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_best_checkpoint(\n\u001b[1;32m    255\u001b[0m     best_trial, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_metric, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_mode\n\u001b[1;32m    256\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: No best trial found. Please check if you specified the correct default metric (metric_score) and mode (min)."
     ]
    }
   ],
   "source": [
    "auto_train_results.best_model\n",
    "best_model = auto_train_results.best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AutoTrainResults' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/ibrahim/Ibrahim_Python_Scripts/ludwig_auto_train.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgaladriel.ing.uni-bayreuth.de/home/ibrahim/Ibrahim_Python_Scripts/ludwig_auto_train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m predictions \u001b[39m=\u001b[39m auto_train_results\u001b[39m.\u001b[39;49mpredict(test_df)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgaladriel.ing.uni-bayreuth.de/home/ibrahim/Ibrahim_Python_Scripts/ludwig_auto_train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpredictions :     \u001b[39m\u001b[39m\"\u001b[39m,predictions)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgaladriel.ing.uni-bayreuth.de/home/ibrahim/Ibrahim_Python_Scripts/ludwig_auto_train.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39my_test:    \u001b[39m\u001b[39m\"\u001b[39m ,y_test)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AutoTrainResults' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "predictions = best_model.predict(test_df)\n",
    "print(\"predictions :     \",predictions)\n",
    "print(\"y_test:    \" ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_stats, _, _ = best_model.evaluate(dataset=test_df)\n",
    "print(eval_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_stats, _, _ = best_model.evaluate(dataset=train_df)\n",
    "print(eval_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\n",
    "\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "r2 = r2_score(y_test,predictions)\n",
    "print(\"mae: \",mae,\" mse: \", mse,\" r2: \", r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
